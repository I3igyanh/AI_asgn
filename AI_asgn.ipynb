{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Genetic Algotithm"
      ],
      "metadata": {
        "id": "6VrZexVdqAo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class GeneticAlgorithm:\n",
        "    def __init__(self, initial_population):\n",
        "        self.initial_population = initial_population\n",
        "        self.result = []\n",
        "\n",
        "    def my_func(self, x):\n",
        "        return 2*x**2 + x - 6\n",
        "\n",
        "    def get_binary_form(self, n):\n",
        "        if n < -15.96875 or n > 15.96875:\n",
        "            raise Exception(\"The initial population should be between -15.96875 and 15.96875\")\n",
        "\n",
        "        x = n\n",
        "        n = abs(n)\n",
        "\n",
        "        integer_part = int(n)\n",
        "        fractional_part = n - integer_part\n",
        "\n",
        "        binary_integer = [int(digit) for digit in format(integer_part, '05b')]\n",
        "        binary_fraction = [int(digit) for digit in format(int(fractional_part * 64), '06b')]  # 6 bits for fraction\n",
        "\n",
        "        binary = binary_integer + binary_fraction\n",
        "\n",
        "        if x < 0:\n",
        "            binary.insert(0, 1)  # Sign bit for negative numbers\n",
        "        else:\n",
        "            binary.insert(0, 0)  # Sign bit for positive numbers\n",
        "\n",
        "        return binary\n",
        ""
      ],
      "metadata": {
        "id": "8zPY3VCKqInR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "source": [
        "'''\n",
        "    Generates a dictionary of binary forms for the population.\n",
        "    '''\n",
        "def generate_binary_dict(self, nums): #Removed extra indentation\n",
        "        if len(nums) < 3:\n",
        "            for i in range(3 - len(nums)):\n",
        "                nums.append(round(random.uniform(-6, 6), 4))\n",
        "\n",
        "        bin_dict = {}\n",
        "        for num in nums:\n",
        "            bin_dict[num] = self.get_binary_form(num)\n",
        "\n",
        "        return bin_dict"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "6brDqSV2rANa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " '''\n",
        "    Finds the fittest individuals, i.e., those whose function value is closest to zero.\n",
        "    '''\n",
        "def fittest(self, nums):\n",
        "        numbers = {}\n",
        "        for num in nums.keys():\n",
        "            numbers[num] = self.my_func(num)\n",
        "            if numbers[num] == 0:\n",
        "                self.result.append(num)\n",
        "\n",
        "        sorted_numbers = sorted(numbers.items(), key=lambda item: abs(item[1]))\n",
        "        fittest_values = dict(sorted_numbers[:2])\n",
        "\n",
        "        binary_form = self.generate_binary_dict(fittest_values)\n",
        "        return binary_form\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r5ywUjwtqp5L"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    Performs uniform crossover to produce offsprings.\n",
        "    '''\n",
        "def crossover(self, nums):\n",
        "        values = list(nums.values())\n",
        "        toss = [random.randint(0, 1) for _ in range(len(values[0]))]\n",
        "\n",
        "        offspring1 = []\n",
        "        offspring2 = []\n",
        "\n",
        "        parent1, parent2 = random.sample(values, 2)\n",
        "        o1 = []\n",
        "        o2 = []\n",
        "        for p1, p2 in zip(parent1, parent2):\n",
        "            if toss.pop(0) == 0:\n",
        "                o1.append(p1)\n",
        "                o2.append(p2)\n",
        "            else:\n",
        "                o1.append(p2)\n",
        "                o2.append(p1)\n",
        "\n",
        "        offspring1.append(o1)\n",
        "        offspring2.append(o2)\n",
        "\n",
        "        return offspring1, offspring2\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "3sLMLugOquIR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    Mutates the offspring by flipping random bits.\n",
        "    '''\n",
        "def mutation(self, of1, of2):\n",
        "        mp = [random.randint(0, 1) for _ in range(len(of1[0]))]\n",
        "\n",
        "        final_offspring = []\n",
        "        for of in of1 + of2:\n",
        "            mutated_offspring = []\n",
        "            for gene, mutation in zip(of, mp):\n",
        "                mutated_offspring.append(gene if mutation == 0 else 1 - gene)\n",
        "            final_offspring.append(mutated_offspring)\n",
        "\n",
        "        return final_offspring\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "UtqA-XmFqxpR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " '''\n",
        "    Converts binary to decimal to produce the next generation.\n",
        "    '''\n",
        "def binary_to_decimal(self, offsprings):\n",
        "        result = []\n",
        "        for of in offsprings:\n",
        "            integer_part = int(''.join(map(str, of[1:6])), 2)\n",
        "            fractional_part = int(''.join(map(str, of[6:])), 2) / 64.0\n",
        "            value = integer_part + fractional_part\n",
        "            if of[0] == 1:\n",
        "                value = -value\n",
        "            result.append(round(value, 4))\n",
        "\n",
        "        result = list(set(result))\n",
        "        return result\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "IySIs71bq1V6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class GeneticAlgorithm:\n",
        "    def __init__(self, initial_population):\n",
        "        self.initial_population = initial_population\n",
        "        self.result = []\n",
        "\n",
        "    def generate_binary_dict(self, nums):\n",
        "        if isinstance(nums, dict):\n",
        "            nums = list(nums.keys())  # Convert dict keys to list\n",
        "        if len(nums) < 3:\n",
        "            for _ in range(3 - len(nums)):\n",
        "                nums.append(round(random.uniform(-6, 6), 4))\n",
        "\n",
        "        bin_dict = {}\n",
        "        for num in nums:\n",
        "            bin_dict[num] = self.get_binary_form(num)\n",
        "\n",
        "        return bin_dict\n",
        "\n",
        "    def get_binary_form(self, num):\n",
        "        # Dummy implementation for binary representation\n",
        "        num = round(num, 4)\n",
        "        if num < 0:\n",
        "            num = abs(num)\n",
        "            sign_bit = 1\n",
        "        else:\n",
        "            sign_bit = 0\n",
        "\n",
        "        integer_part = int(num)\n",
        "        fractional_part = num - integer_part\n",
        "\n",
        "        integer_bits = bin(integer_part)[2:].zfill(5)\n",
        "        fractional_bits = ''.join(str(int(fractional_part * (2**i) % 2)) for i in range(6))\n",
        "\n",
        "        return [sign_bit] + list(map(int, integer_bits + fractional_bits))\n",
        "\n",
        "    def fittest(self, nums):\n",
        "        numbers = {}\n",
        "        for num in nums.keys():\n",
        "            numbers[num] = self.my_func(num)\n",
        "            if numbers[num] == 0:\n",
        "                self.result.append(num)\n",
        "\n",
        "        sorted_numbers = sorted(numbers.items(), key=lambda item: abs(item[1]))\n",
        "        fittest_values = dict(sorted_numbers[:2])\n",
        "\n",
        "        binary_form = self.generate_binary_dict(fittest_values)\n",
        "        return binary_form\n",
        "\n",
        "    def my_func(self, num):\n",
        "        # Dummy fitness function\n",
        "        return num**2 - 1\n",
        "\n",
        "    def crossover(self, nums):\n",
        "        values = list(nums.values())\n",
        "        offspring1, offspring2 = [], []\n",
        "\n",
        "        for i in range(len(values) - 1):\n",
        "            parent1, parent2 = random.sample(values, 2)\n",
        "            o1, o2 = [], []\n",
        "            for p1, p2 in zip(parent1, parent2):\n",
        "                toss = random.randint(0, 1)\n",
        "                o1.append(p1 if toss == 0 else p2)\n",
        "                o2.append(p2 if toss == 0 else p1)\n",
        "\n",
        "            offspring1.append(o1)\n",
        "            offspring2.append(o2)\n",
        "\n",
        "        return offspring1, offspring2\n",
        "\n",
        "    def mutation(self, of1, of2):\n",
        "        final_offspring = []\n",
        "        for of in of1 + of2:\n",
        "            mutated_offspring = [\n",
        "                gene if random.random() > 0.1 else 1 - gene  # 10% mutation probability\n",
        "                for gene in of\n",
        "            ]\n",
        "            final_offspring.append(mutated_offspring)\n",
        "\n",
        "        return final_offspring\n",
        "\n",
        "    def binary_to_decimal(self, offsprings):\n",
        "        result = []\n",
        "        for of in offsprings:\n",
        "            sign_bit = of[0]\n",
        "            integer_part = int(''.join(map(str, of[1:6])), 2)\n",
        "            fractional_part = int(''.join(map(str, of[6:])), 2) / 64.0\n",
        "\n",
        "            value = integer_part + fractional_part\n",
        "            if sign_bit == 1:\n",
        "                value = -value\n",
        "\n",
        "            value = max(min(value, 15.96875), -15.96875)\n",
        "            result.append(round(value, 4))\n",
        "\n",
        "        return list(set(result))\n",
        "\n",
        "    def find(self):\n",
        "        initial_value = self.initial_population\n",
        "        for i in range(10):\n",
        "            bin_dict = self.generate_binary_dict(initial_value)\n",
        "            fittest_chromosomes = self.fittest(bin_dict)\n",
        "            o1, o2 = self.crossover(fittest_chromosomes)\n",
        "            next_generation = self.mutation(o1, o2)\n",
        "            initial_value = self.binary_to_decimal(next_generation)\n",
        "            print(f\"{i + 1} generation: {initial_value}\")\n",
        "\n",
        "        self.result = list(set(self.result))\n",
        "        print(f\"The roots are: {self.result}\")\n",
        "\n",
        "# Example Usage\n",
        "initial_population = [5.25, -3.75, 7.5]\n",
        "ga = GeneticAlgorithm(initial_population=initial_population)\n",
        "ga.find()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeLzIdGzy8h_",
        "outputId": "997cde46-ec75-4c5c-8543-56987df28386"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 generation: [-15.625, 1.375, -15.9688, 5.2188]\n",
            "2 generation: [3.625, 1.1875, 3.2188, 3.1562]\n",
            "3 generation: [0.0938, -15.9688, 11.0938, 1.5625]\n",
            "4 generation: [2.2656, 11.0312, 5.2969, 6.0625]\n",
            "5 generation: [1.3906, -15.9688, -2.0469, 15.9688]\n",
            "6 generation: [2.1094, 15.9688, -2.0625, -1.25]\n",
            "7 generation: [-15.9688, -5.125, -3.125, -1.125]\n",
            "8 generation: [-3.0, 15.9688, -3.0625, -1.0625]\n",
            "9 generation: [1.5, -15.9688, -1.4844]\n",
            "10 generation: [1.4531, 9.3438, 1.2344, -1.3906]\n",
            "The roots are: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class GeneticAlgorithm:\n",
        "    def __init__(self, initial_population):\n",
        "        self.initial_population = initial_population\n",
        "        self.result = []\n",
        "\n",
        "    def generate_binary_dict(self, nums):\n",
        "        if not isinstance(nums, list):\n",
        "            nums = list(nums.keys())\n",
        "        if len(nums) < 3:\n",
        "            for _ in range(3 - len(nums)):\n",
        "                nums.append(round(random.uniform(-6, 6), 4))\n",
        "\n",
        "        bin_dict = {}\n",
        "        for num in nums:\n",
        "            bin_dict[num] = self.get_binary_form(num)\n",
        "\n",
        "        return bin_dict\n",
        "\n",
        "    def get_binary_form(self, num):\n",
        "        num = round(num, 4)\n",
        "        if num < 0:\n",
        "            num = abs(num)\n",
        "            sign_bit = 1\n",
        "        else:\n",
        "            sign_bit = 0\n",
        "\n",
        "        integer_part = int(num)\n",
        "        fractional_part = num - integer_part\n",
        "\n",
        "        integer_bits = bin(integer_part)[2:].zfill(5)\n",
        "        fractional_bits = ''.join(str(int(fractional_part * (2**i) % 2)) for i in range(6))\n",
        "\n",
        "        return [sign_bit] + list(map(int, integer_bits + fractional_bits))\n",
        "\n",
        "    def fittest(self, nums):\n",
        "        numbers = {}\n",
        "        for num in nums.keys():\n",
        "            numbers[num] = self.my_func(num)\n",
        "            if numbers[num] == 0:\n",
        "                self.result.append(num)\n",
        "\n",
        "        if not self.result:\n",
        "            print(\"No roots found in this generation.\")\n",
        "\n",
        "        sorted_numbers = sorted(numbers.items(), key=lambda item: abs(item[1]))\n",
        "        fittest_values = dict(sorted_numbers[:2])\n",
        "\n",
        "        binary_form = self.generate_binary_dict(fittest_values)\n",
        "        return binary_form\n",
        "\n",
        "    def my_func(self, num):\n",
        "        return num**2 - 1\n",
        "\n",
        "    def crossover(self, nums):\n",
        "        values = list(nums.values())\n",
        "        offspring1, offspring2 = [], []\n",
        "\n",
        "        for i in range(len(values) - 1):\n",
        "            parent1, parent2 = random.sample(values, 2)\n",
        "            o1, o2 = [], []\n",
        "            for p1, p2 in zip(parent1, parent2):\n",
        "                toss = random.randint(0, 1)\n",
        "                o1.append(p1 if toss == 0 else p2)\n",
        "                o2.append(p2 if toss == 0 else p1)\n",
        "\n",
        "            offspring1.append(o1)\n",
        "            offspring2.append(o2)\n",
        "\n",
        "        return offspring1, offspring2\n",
        "\n",
        "    def mutation(self, of1, of2):\n",
        "        final_offspring = []\n",
        "        for of in of1 + of2:\n",
        "            mutated_offspring = [\n",
        "                gene if random.random() > 0.1 else 1 - gene  # 10% mutation probability\n",
        "                for gene in of\n",
        "            ]\n",
        "            final_offspring.append(mutated_offspring)\n",
        "\n",
        "        return final_offspring\n",
        "\n",
        "    def binary_to_decimal(self, offsprings):\n",
        "        result = []\n",
        "        for of in offsprings:\n",
        "            sign_bit = of[0]\n",
        "            integer_part = int(''.join(map(str, of[1:6])), 2)\n",
        "            fractional_part = int(''.join(map(str, of[6:])), 2) / 64.0\n",
        "\n",
        "            value = integer_part + fractional_part\n",
        "            if sign_bit == 1:\n",
        "                value = -value\n",
        "\n",
        "            value = max(min(value, 15.96875), -15.96875)\n",
        "            result.append(round(value, 4))\n",
        "\n",
        "        return list(set(result))\n",
        "\n",
        "    def find(self):\n",
        "        initial_value = self.initial_population\n",
        "        for i in range(10):\n",
        "            bin_dict = self.generate_binary_dict(initial_value)\n",
        "            print(f\"Generation {i + 1} binary dict: {bin_dict}\")\n",
        "\n",
        "            fittest_chromosomes = self.fittest(bin_dict)\n",
        "            print(f\"Generation {i + 1} fittest chromosomes: {fittest_chromosomes}\")\n",
        "\n",
        "            if not fittest_chromosomes:\n",
        "                print(f\"No fittest chromosomes found in generation {i + 1}.\")\n",
        "                continue\n",
        "\n",
        "            o1, o2 = self.crossover(fittest_chromosomes)\n",
        "            print(f\"Generation {i + 1} offspring: {o1}, {o2}\")\n",
        "\n",
        "            next_generation = self.mutation(o1, o2)\n",
        "            print(f\"Generation {i + 1} mutated offspring: {next_generation}\")\n",
        "\n",
        "            initial_value = self.binary_to_decimal(next_generation)\n",
        "            print(f\"{i + 1} generation: {initial_value}\")\n",
        "\n",
        "        self.result = list(set(self.result))\n",
        "        if self.result:\n",
        "            print(f\"The roots are: {self.result}\")\n",
        "        else:\n",
        "            print(\"No roots found after 10 generations.\")\n",
        "\n",
        "# Example Usage\n",
        "initial_population = [5.25, -3.75, 7.5]\n",
        "ga = GeneticAlgorithm(initial_population=initial_population)\n",
        "ga.find()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uARXAQsu2F7S",
        "outputId": "0afce57c-6cce-42da-c66d-25a147b586f2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1 binary dict: {5.25: [0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0], -3.75: [1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0], 7.5: [0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0]}\n",
            "No roots found in this generation.\n",
            "Generation 1 fittest chromosomes: {-3.75: [1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0], 5.25: [0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0], 3.2953: [0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1]}\n",
            "Generation 1 offspring: [[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0], [0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0]], [[1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1], [1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]]\n",
            "Generation 1 mutated offspring: [[0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0], [0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0], [1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1], [1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]]\n",
            "1 generation: [1.375, -3.375, -3.1406, 13.125]\n",
            "Generation 2 binary dict: {1.375: [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0], -3.375: [1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0], -3.1406: [1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0], 13.125: [0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0]}\n",
            "No roots found in this generation.\n",
            "Generation 2 fittest chromosomes: {1.375: [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0], -3.1406: [1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0], -4.6859: [1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1]}\n",
            "Generation 2 offspring: [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [[1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1], [0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]]\n",
            "Generation 2 mutated offspring: [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1], [1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1]]\n",
            "2 generation: [-0.0625, -5.0625, -2.9531, -5.9531]\n",
            "Generation 3 binary dict: {-0.0625: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], -5.0625: [1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0], -2.9531: [1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0], -5.9531: [1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0]}\n",
            "No roots found in this generation.\n",
            "Generation 3 fittest chromosomes: {-0.0625: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], -2.9531: [1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0], 2.4536: [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0]}\n",
            "Generation 3 offspring: [[1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0], [1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]], [[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0], [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0]]\n",
            "Generation 3 mutated offspring: [[1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0], [1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0], [0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1]]\n",
            "3 generation: [-0.1562, -4.3438, -2.4688, 6.2344]\n",
            "Generation 4 binary dict: {-0.1562: [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], -4.3438: [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1], -2.4688: [1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1], 6.2344: [0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1]}\n",
            "No roots found in this generation.\n",
            "Generation 4 fittest chromosomes: {-0.1562: [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], -2.4688: [1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1], 2.3794: [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0]}\n",
            "Generation 4 offspring: [[1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [[1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1], [1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1]]\n",
            "Generation 4 mutated offspring: [[1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1], [1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1]]\n",
            "4 generation: [-0.4844, -0.0625, -0.3281, -2.2344]\n",
            "Generation 5 binary dict: {-0.4844: [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], -0.0625: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], -0.3281: [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0], -2.2344: [1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1]}\n",
            "No roots found in this generation.\n",
            "Generation 5 fittest chromosomes: {-0.4844: [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], -0.3281: [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0], -4.6398: [1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0]}\n",
            "Generation 5 offspring: [[1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1]], [[1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0], [1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0]]\n",
            "Generation 5 mutated offspring: [[0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1], [1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1], [0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0]]\n",
            "5 generation: [-0.4531, 2.0781, 4.3438, 4.0938]\n",
            "Generation 6 binary dict: {-0.4531: [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0], 2.0781: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0], 4.3438: [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1], 4.0938: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1]}\n",
            "No roots found in this generation.\n",
            "Generation 6 fittest chromosomes: {-0.4531: [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0], 2.0781: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0], 4.7212: [0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1]}\n",
            "Generation 6 offspring: [[1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0], [1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0]]\n",
            "Generation 6 mutated offspring: [[1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0], [1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0], [0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0]]\n",
            "6 generation: [-15.9688, -4.2344, 4.0938, 9.8438]\n",
            "Generation 7 binary dict: {-15.9688: [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1], -4.2344: [1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1], 4.0938: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1], 9.8438: [0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1]}\n",
            "No roots found in this generation.\n",
            "Generation 7 fittest chromosomes: {4.0938: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1], -4.2344: [1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1], -4.3526: [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1]}\n",
            "Generation 7 offspring: [[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1], [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1]], [[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1], [1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1]]\n",
            "Generation 7 mutated offspring: [[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1], [1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1], [1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1]]\n",
            "7 generation: [-15.9688, -4.1719, 4.0469, -4.3594]\n",
            "Generation 8 binary dict: {-15.9688: [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1], -4.1719: [1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1], 4.0469: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], -4.3594: [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1]}\n",
            "No roots found in this generation.\n",
            "Generation 8 fittest chromosomes: {4.0469: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], -4.1719: [1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1], -1.8678: [1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1]}\n",
            "Generation 8 offspring: [[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1], [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1]], [[1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1]]\n",
            "Generation 8 mutated offspring: [[1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1], [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1], [1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1]]\n",
            "8 generation: [-0.3906, 1.1406, -13.1094, -4.0469]\n",
            "Generation 9 binary dict: {-0.3906: [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0], 1.1406: [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0], -13.1094: [1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1], -4.0469: [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]}\n",
            "No roots found in this generation.\n",
            "Generation 9 fittest chromosomes: {1.1406: [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0], -0.3906: [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0], -3.6203: [1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1]}\n",
            "Generation 9 offspring: [[1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0], [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0], [0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1]]\n",
            "Generation 9 mutated offspring: [[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0], [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0], [0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1]]\n",
            "9 generation: [-0.0938, 2.1875, 3.2969, -1.0625]\n",
            "Generation 10 binary dict: {-0.0938: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], 2.1875: [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0], 3.2969: [0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1], -1.0625: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0]}\n",
            "No roots found in this generation.\n",
            "Generation 10 fittest chromosomes: {-1.0625: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0], -0.0938: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], -1.4412: [1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0]}\n",
            "Generation 10 offspring: [[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0], [1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0]], [[1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]]\n",
            "Generation 10 mutated offspring: [[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1], [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0], [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1]]\n",
            "10 generation: [-1.0938, -1.2344, -4.0469, -1.0312]\n",
            "No roots found after 10 generations.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Import the required modules.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import InputLayer, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris['data']\n",
        "y = iris['target']\n",
        "names = iris['target_names']\n",
        "feature_names = iris['feature_names']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.25, random_state=2)\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "8zAs5ORf3CuW"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer(shape=(4,)))\n",
        "model.add(Dense(7,activation='relu'))\n",
        "model.add(Dense(7,activation='relu'))\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "history = model.fit(X_train,Y_train, epochs=50,validation_data=(X_test,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Yt26j7Wc3e0y",
        "outputId": "3d9c2c21-74bb-4a67-98dc-70af97fcfdb0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │              \u001b[38;5;34m35\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m24\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m115\u001b[0m (460.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">115</span> (460.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m115\u001b[0m (460.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">115</span> (460.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.3894 - loss: 1.1971 - val_accuracy: 0.5000 - val_loss: 1.1762\n",
            "Epoch 2/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3640 - loss: 1.1978 - val_accuracy: 0.5000 - val_loss: 1.1645\n",
            "Epoch 3/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4118 - loss: 1.1954 - val_accuracy: 0.5263 - val_loss: 1.1537\n",
            "Epoch 4/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4070 - loss: 1.1819 - val_accuracy: 0.5526 - val_loss: 1.1443\n",
            "Epoch 5/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4314 - loss: 1.1525 - val_accuracy: 0.5526 - val_loss: 1.1358\n",
            "Epoch 6/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4307 - loss: 1.1557 - val_accuracy: 0.5789 - val_loss: 1.1278\n",
            "Epoch 7/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4576 - loss: 1.1475 - val_accuracy: 0.6053 - val_loss: 1.1201\n",
            "Epoch 8/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4418 - loss: 1.1501 - val_accuracy: 0.6316 - val_loss: 1.1129\n",
            "Epoch 9/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5298 - loss: 1.1203 - val_accuracy: 0.6316 - val_loss: 1.1065\n",
            "Epoch 10/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5021 - loss: 1.1205 - val_accuracy: 0.6579 - val_loss: 1.1000\n",
            "Epoch 11/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4859 - loss: 1.1130 - val_accuracy: 0.6579 - val_loss: 1.0937\n",
            "Epoch 12/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4786 - loss: 1.1188 - val_accuracy: 0.6579 - val_loss: 1.0875\n",
            "Epoch 13/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4942 - loss: 1.0942 - val_accuracy: 0.6579 - val_loss: 1.0813\n",
            "Epoch 14/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5449 - loss: 1.0906 - val_accuracy: 0.6579 - val_loss: 1.0748\n",
            "Epoch 15/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5531 - loss: 1.0771 - val_accuracy: 0.6579 - val_loss: 1.0680\n",
            "Epoch 16/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5649 - loss: 1.0762 - val_accuracy: 0.7368 - val_loss: 1.0615\n",
            "Epoch 17/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6179 - loss: 1.0608 - val_accuracy: 0.7368 - val_loss: 1.0542\n",
            "Epoch 18/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6321 - loss: 1.0581 - val_accuracy: 0.7368 - val_loss: 1.0471\n",
            "Epoch 19/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6372 - loss: 1.0479 - val_accuracy: 0.8158 - val_loss: 1.0399\n",
            "Epoch 20/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6963 - loss: 1.0398 - val_accuracy: 0.7632 - val_loss: 1.0326\n",
            "Epoch 21/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7445 - loss: 1.0254 - val_accuracy: 0.7632 - val_loss: 1.0250\n",
            "Epoch 22/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7379 - loss: 1.0221 - val_accuracy: 0.7895 - val_loss: 1.0175\n",
            "Epoch 23/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7979 - loss: 1.0039 - val_accuracy: 0.7895 - val_loss: 1.0089\n",
            "Epoch 24/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7448 - loss: 0.9997 - val_accuracy: 0.7632 - val_loss: 1.0006\n",
            "Epoch 25/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7188 - loss: 0.9966 - val_accuracy: 0.7632 - val_loss: 0.9922\n",
            "Epoch 26/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7427 - loss: 0.9807 - val_accuracy: 0.7895 - val_loss: 0.9833\n",
            "Epoch 27/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7469 - loss: 0.9732 - val_accuracy: 0.7895 - val_loss: 0.9734\n",
            "Epoch 28/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7609 - loss: 0.9540 - val_accuracy: 0.7632 - val_loss: 0.9633\n",
            "Epoch 29/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7963 - loss: 0.9493 - val_accuracy: 0.7632 - val_loss: 0.9531\n",
            "Epoch 30/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7936 - loss: 0.9282 - val_accuracy: 0.7368 - val_loss: 0.9427\n",
            "Epoch 31/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8049 - loss: 0.9156 - val_accuracy: 0.7368 - val_loss: 0.9321\n",
            "Epoch 32/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7586 - loss: 0.9214 - val_accuracy: 0.7368 - val_loss: 0.9215\n",
            "Epoch 33/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7924 - loss: 0.9007 - val_accuracy: 0.7368 - val_loss: 0.9100\n",
            "Epoch 34/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7982 - loss: 0.8830 - val_accuracy: 0.7368 - val_loss: 0.8980\n",
            "Epoch 35/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7655 - loss: 0.8874 - val_accuracy: 0.7632 - val_loss: 0.8858\n",
            "Epoch 36/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7612 - loss: 0.8804 - val_accuracy: 0.7895 - val_loss: 0.8731\n",
            "Epoch 37/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7695 - loss: 0.8521 - val_accuracy: 0.7895 - val_loss: 0.8591\n",
            "Epoch 38/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7981 - loss: 0.8378 - val_accuracy: 0.7895 - val_loss: 0.8448\n",
            "Epoch 39/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7939 - loss: 0.8355 - val_accuracy: 0.7895 - val_loss: 0.8298\n",
            "Epoch 40/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8022 - loss: 0.8048 - val_accuracy: 0.7895 - val_loss: 0.8133\n",
            "Epoch 41/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8095 - loss: 0.7939 - val_accuracy: 0.8158 - val_loss: 0.7958\n",
            "Epoch 42/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7929 - loss: 0.7894 - val_accuracy: 0.8158 - val_loss: 0.7776\n",
            "Epoch 43/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7918 - loss: 0.7625 - val_accuracy: 0.8158 - val_loss: 0.7591\n",
            "Epoch 44/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8360 - loss: 0.7353 - val_accuracy: 0.8158 - val_loss: 0.7396\n",
            "Epoch 45/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7923 - loss: 0.7351 - val_accuracy: 0.8158 - val_loss: 0.7196\n",
            "Epoch 46/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8146 - loss: 0.6882 - val_accuracy: 0.8158 - val_loss: 0.6993\n",
            "Epoch 47/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8083 - loss: 0.6926 - val_accuracy: 0.8158 - val_loss: 0.6788\n",
            "Epoch 48/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7917 - loss: 0.6844 - val_accuracy: 0.8421 - val_loss: 0.6584\n",
            "Epoch 49/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8188 - loss: 0.6760 - val_accuracy: 0.8421 - val_loss: 0.6386\n",
            "Epoch 50/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7865 - loss: 0.6674 - val_accuracy: 0.8421 - val_loss: 0.6198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "class HebbianNeuron(object):\n",
        "    def __init__(self, shape, learning_rate =1, epoch=1):\n",
        "        self.shape = shape\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epoch\n",
        "        self.weights = np.zeros(self.shape)\n",
        "        self.bias = np.zeros(1)\n",
        "\n",
        "    def train(self, inputs, targets):\n",
        "        for epoch in range(self.epochs):\n",
        "            for i in range(len(inputs)):\n",
        "                input_pattern = inputs[i]\n",
        "                target = targets[i]\n",
        "    #           output = np.dot(self.weights, input_pattern)\n",
        "                self.weights += self.learning_rate * target * input_pattern\n",
        "                self.bias += self.learning_rate * target\n",
        "                print(\"Weight updated: \" + str(self.weights[0]))\n",
        "                print(\"Weight updated: \" + str(self.weights[1]))\n",
        "                print(\"Bias updated: \" + str(self.bias))\n",
        "                print(\"----------------------------------------\")\n",
        "        return self.weights, self.bias\n",
        "\n",
        "    def predict(self, inputs, ret = False):\n",
        "        self.out_raw =[]\n",
        "        self.out_val =[]\n",
        "        for input_pattern in inputs:\n",
        "            output = input_pattern.dot(self.weights)+self.bias\n",
        "            self.out_raw.append(output)\n",
        "            self.out_val.append(1 if output>0 else -1)\n",
        "            if not ret:\n",
        "                print(f\"Input: {input_pattern}, Output:{output > 0}\")\n",
        "\n",
        "    def TruthTable(self, input, input_labels, output_labels):\n",
        "        table = pd.DataFrame(input, columns = input_labels)\n",
        "\n",
        "        self.predict(input,True)\n",
        "\n",
        "\n",
        "        table[output_labels] = pd.Series(self.out_val)\n",
        "        return table\n",
        "inputs = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])\n",
        "targets = np.array([-1,1,1,1])\n",
        "OR = HebbianNeuron(inputs.shape[1])\n",
        "\n",
        "OR.train(inputs, targets)\n",
        "OR.predict(inputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31fmpdyh37sl",
        "outputId": "760727ed-85e3-4734-9ead-9afffa7f8e75"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight updated: 1.0\n",
            "Weight updated: 1.0\n",
            "Bias updated: [-1.]\n",
            "----------------------------------------\n",
            "Weight updated: 0.0\n",
            "Weight updated: 2.0\n",
            "Bias updated: [0.]\n",
            "----------------------------------------\n",
            "Weight updated: 1.0\n",
            "Weight updated: 1.0\n",
            "Bias updated: [1.]\n",
            "----------------------------------------\n",
            "Weight updated: 2.0\n",
            "Weight updated: 2.0\n",
            "Bias updated: [2.]\n",
            "----------------------------------------\n",
            "Input: [-1 -1], Output:[False]\n",
            "Input: [-1  1], Output:[ True]\n",
            "Input: [ 1 -1], Output:[ True]\n",
            "Input: [1 1], Output:[ True]\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, learning_rate=0.1, epochs=100):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.weights = np.random.rand(X.shape[1])\n",
        "        self.bias = np.random.rand(1)\n",
        "        for _ in range(self.epochs):\n",
        "            for inputs, target in zip(X, y):\n",
        "                prediction = self.predict(inputs)\n",
        "                error = target - prediction\n",
        "                self.weights += self.learning_rate * error * inputs\n",
        "                self.bias += self.learning_rate * error\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
        "        return self._activation(weighted_sum)\n",
        "\n",
        "    def _activation(self, z):\n",
        "        return 1 if z >= 0 else 0\n",
        "\n",
        "\n",
        "model = Perceptron()\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = [0, 0, 0, 1]\n",
        "model.fit(X, y)\n",
        "\n",
        "# Call predict instead of print_table\n",
        "print(model.predict([0, 0]))\n",
        "print(model.predict([0, 1]))\n",
        "print(model.predict([1, 0]))\n",
        "print(model.predict([1, 1]))\n",
        "\n",
        "print(\"Weights: \", model.weights)\n",
        "print(\"Bias: \", model.bias)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJmR8hhu4ShW",
        "outputId": "48fcb766-fa58-48e7-9443-bbf31f222355"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "Weights:  [0.44463671 0.3315523 ]\n",
            "Bias:  [-0.62642072]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Initialize weights\n",
        "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size)\n",
        "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size)\n",
        "\n",
        "        # Initialize the biases\n",
        "        self.bias_hidden = np.zeros((1, self.hidden_size))\n",
        "        self.bias_output = np.zeros((1, self.output_size))\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def feedforward(self, X):\n",
        "        # Input to hidden\n",
        "        self.hidden_activation = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
        "        self.hidden_output = self.sigmoid(self.hidden_activation)\n",
        "\n",
        "        # Hidden to output\n",
        "        self.output_activation = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
        "        self.predicted_output = self.sigmoid(self.output_activation)\n",
        "\n",
        "        return self.predicted_output\n",
        "\n",
        "    def backward(self, X, y, learning_rate):\n",
        "        # Compute the output layer error\n",
        "        output_error = y - self.predicted_output\n",
        "        output_delta = output_error * self.sigmoid_derivative(self.predicted_output)\n",
        "\n",
        "        # Compute the hidden layer error\n",
        "        hidden_error = np.dot(output_delta, self.weights_hidden_output.T)\n",
        "        hidden_delta = hidden_error * self.sigmoid_derivative(self.hidden_output)\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.weights_hidden_output += np.dot(self.hidden_output.T, output_delta) * learning_rate\n",
        "        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
        "        self.weights_input_hidden += np.dot(X.T, hidden_delta) * learning_rate\n",
        "        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    def train(self, X, y, epochs, learning_rate):\n",
        "        for epoch in range(epochs):\n",
        "            output = self.feedforward(X)\n",
        "            self.backward(X, y, learning_rate)\n",
        "            if epoch % 4000 == 0:\n",
        "                loss = np.mean(np.square(y - output))\n",
        "                print(f\"Epoch {epoch}, Loss:{loss}\")\n",
        "\n",
        "\n",
        "\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "nn = NeuralNetwork(input_size=2, hidden_size=4, output_size=1)\n",
        "nn.train(X, y, epochs=10000, learning_rate=0.1)\n",
        "\n",
        "# Test the trained model\n",
        "output = nn.feedforward(X)\n",
        "print(\"Predictions after training:\")\n",
        "print(output)\n",
        "\n",
        "def make_table(outputs):\n",
        "    inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
        "    i = 0\n",
        "    print(\"Truth table of X-OR Gate\\n\")\n",
        "    for output in outputs:\n",
        "        if output > 0.9:\n",
        "            result = \"True\"\n",
        "        else:\n",
        "            result = \"False\"\n",
        "\n",
        "        print(f\"{inputs[i]} : {result}\")\n",
        "        i += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8L6mcbY42kd",
        "outputId": "fc8ed755-0a5b-4737-b37b-acd206dfabe3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss:0.33414589786728993\n",
            "Epoch 4000, Loss:0.00664335892422387\n",
            "Epoch 8000, Loss:0.002266402484363839\n",
            "Predictions after training:\n",
            "[[0.02754092]\n",
            " [0.96111397]\n",
            " [0.95437449]\n",
            " [0.04829135]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class  NaiveBayes:\n",
        "    def __init__(self):\n",
        "\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "\n",
        "        likelihoods: Likelihood of each feature per class\n",
        "        class_priors: Prior probabilities of classes\n",
        "        pred_priors: Prior probabilities of features\n",
        "        features: All features of dataset\n",
        "        \"\"\"\n",
        "        self.features = list\n",
        "        self.likelihoods = {}\n",
        "        self.class_priors = {}\n",
        "        self.pred_priors = {}\n",
        "\n",
        "        self.X_train = np.array\n",
        "        self.y_train = np.array\n",
        "        self.train_size = int\n",
        "        self.num_feats = int\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        self.features = list(X.columns)\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "        self.train_size = X.shape[0]\n",
        "        self.num_feats = X.shape[1]\n",
        "\n",
        "        for feature in self.features:\n",
        "            self.likelihoods[feature] = {}\n",
        "            self.pred_priors[feature] = {}\n",
        "\n",
        "            for feat_val in np.unique(self.X_train[feature]):\n",
        "                self.pred_priors[feature].update({feat_val: 0})\n",
        "\n",
        "                for outcome in np.unique(self.y_train):\n",
        "                    self.likelihoods[feature].update({feat_val+'_'+outcome:0})\n",
        "                    self.class_priors.update({outcome: 0})\n",
        "\n",
        "        self._calc_class_prior()\n",
        "        self._calc_likelihoods()\n",
        "        self._calc_predictor_prior()\n",
        "\n",
        "    def _calc_class_prior(self):\n",
        "\n",
        "        \"\"\" P(c) - Prior Class Probability \"\"\"\n",
        "\n",
        "        for outcome in np.unique(self.y_train):\n",
        "            outcome_count = sum(self.y_train == outcome)\n",
        "            self.class_priors[outcome] = outcome_count / self.train_size\n",
        "\n",
        "    def _calc_likelihoods(self):\n",
        "\n",
        "        \"\"\" P(x|c) - Likelihood \"\"\"\n",
        "\n",
        "        for feature in self.features:\n",
        "\n",
        "            for outcome in np.unique(self.y_train):\n",
        "                outcome_count = sum(self.y_train == outcome)\n",
        "                feat_likelihood = self.X_train[feature][self.y_train[self.y_train == outcome].index.values.tolist()].value_counts().to_dict()\n",
        "\n",
        "                for feat_val, count in feat_likelihood.items():\n",
        "                    self.likelihoods[feature][feat_val + '_' + outcome] = count/outcome_count\n",
        "\n",
        "\n",
        "    def _calc_predictor_prior(self):\n",
        "\n",
        "        \"\"\" P(x) - Evidence \"\"\"\n",
        "\n",
        "        for feature in self.features:\n",
        "            feat_vals = self.X_train[feature].value_counts().to_dict()\n",
        "\n",
        "            for feat_val, count in feat_vals.items():\n",
        "                self.pred_priors[feature][feat_val] = count/self.train_size\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        \"\"\" Calculates Posterior probability P(c|x) \"\"\"\n",
        "\n",
        "        results = []\n",
        "        X = np.array(X)\n",
        "\n",
        "        for query in X:\n",
        "            probs_outcome = {}\n",
        "            for outcome in np.unique(self.y_train):\n",
        "                        prior = self.class_priors[outcome]\n",
        "                        likelihood = 1\n",
        "                        evidence = 1\n",
        "\n",
        "                        for feat, feat_val in zip(self.features, query):\n",
        "                            likelihood *= self.likelihoods[feat][feat_val + '_' + outcome]\n",
        "                            evidence *= self.pred_priors[feat][feat_val]\n",
        "\n",
        "                        # posterior = (likelihood * prior) / (evidence)\n",
        "                        posterior = (likelihood * prior)\n",
        "\n",
        "                        probs_outcome[outcome] = posterior\n",
        "\n",
        "            result = max(probs_outcome, key = lambda x: probs_outcome[x])\n",
        "            print(probs_outcome)\n",
        "            results.append(result)\n",
        "\n",
        "        return np.array(results)\n",
        "\n",
        "\n",
        "def accuracy_score(y_true, y_pred):\n",
        "\n",
        "    \"\"\"\tscore = (y_true - y_pred) / len(y_true) \"\"\"\n",
        "\n",
        "    return round(float(sum(y_pred == y_true))/float(len(y_true)) * 100 ,2)\n"
      ],
      "metadata": {
        "id": "udyOJG3X5T8s"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"Color\": [\"White\", \"Green\", \"Green\", \"White\", \"Green\", \"White\", \"White\", \"White\"],\n",
        "    \"Legs\": [3, 2, 3, 3, 2, 2, 2, 2],\n",
        "    \"Height\": [\"Short\", \"Tall\", \"Short\", \"Short\", \"Short\", \"Tall\", \"Tall\", \"Short\"],\n",
        "    \"Smelly\": [\"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\"],\n",
        "    \"Species\": [\"M\", \"M\", \"M\", \"M\", \"H\", \"H\", \"H\", \"H\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df['Legs'] = df['Legs'].astype('str')\n",
        "\n",
        "X = df.drop(['Species'], axis = 1)\n",
        "y = df['Species']\n",
        "nb_clf = NaiveBayes()\n",
        "nb_clf.fit(X, y)\n",
        "\n",
        "print(\"Train Accuracy: {}\".format(accuracy_score(y, nb_clf.predict(X))))\n",
        "\n",
        "query1 = np.array([['Green','2','Short','Yes']])\n",
        "print(\"prediction 1:- {} ---> {}\".format(query1, nb_clf.predict(query1)))\n",
        "print(\"\\n\")\n",
        "query2 = np.array([['White','2','Short','Yes']])\n",
        "print(\"prediction 2:- {} ---> {}\".format(query2, nb_clf.predict(query2)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEKkoisc5by9",
        "outputId": "c7615606-b95a-4193-b820-100954c5a54a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'H': 0.0, 'M': 0.10546875}\n",
            "{'H': 0.046875, 'M': 0.00390625}\n",
            "{'H': 0.0, 'M': 0.10546875}\n",
            "{'H': 0.0, 'M': 0.10546875}\n",
            "{'H': 0.046875, 'M': 0.01171875}\n",
            "{'H': 0.140625, 'M': 0.00390625}\n",
            "{'H': 0.140625, 'M': 0.00390625}\n",
            "{'H': 0.046875, 'M': 0.03515625}\n",
            "Train Accuracy: 87.5\n",
            "{'H': 0.015625, 'M': 0.03515625}\n",
            "prediction 1:- [['Green' '2' 'Short' 'Yes']] ---> ['M']\n",
            "\n",
            "\n",
            "{'H': 0.046875, 'M': 0.03515625}\n",
            "prediction 2:- [['White' '2' 'Short' 'Yes']] ---> ['H']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"Color\": [\"yellow\", \"Red\", \"Red\", \"Yellow\", \"Yellow\", \"Yellow\", \"Yellow\", \"Yellow\", \"Red\", \"Red\"],\n",
        "    \"Type\": [\"Sports\", \"Sports\", \"Sports\", \"Sports\", \"Sports\", \"SUV\", \"SUV\", \"SUV\", \"SUV\", \"Sports\"],\n",
        "    \"Origin\": [\"Domestic\", \"Domestic\", \"Domestic\", \"Domestic\", \"Imported\", \"Imported\", \"Imported\", \"Domestic\", \"Imported\", \"Imported\"],\n",
        "    \"Stolen\": [\"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "X = df.drop(['Stolen'], axis =1)\n",
        "y = df['Stolen']\n",
        "\n",
        "nb_clf = NaiveBayes()\n",
        "nb_clf.fit(X, y)\n",
        "\n",
        "print(\"Train Accuracy: {}\".format(accuracy_score(y, nb_clf.predict(X))))\n",
        "\n",
        "query1 = np.array([['Red','Sports','Domestic']])\n",
        "print(\"prediction 1:- {} ---> {}\".format(query1, nb_clf.predict(query1)))\n",
        "print(\"\\n\")\n",
        "query2 = np.array([['Yellow','SUV','Imported']])\n",
        "print(\"prediction 2:- {} ---> {}\".format(query2, nb_clf.predict(query2)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5csg0Ygn52Mz",
        "outputId": "ca68f31a-5809-4ad2-a5c4-d139c7d2172f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'No': 0.0, 'Yes': 0.03200000000000001}\n",
            "{'No': 0.04800000000000001, 'Yes': 0.06400000000000002}\n",
            "{'No': 0.04800000000000001, 'Yes': 0.06400000000000002}\n",
            "{'No': 0.072, 'Yes': 0.06400000000000002}\n",
            "{'No': 0.048, 'Yes': 0.09600000000000002}\n",
            "{'No': 0.072, 'Yes': 0.024000000000000004}\n",
            "{'No': 0.072, 'Yes': 0.024000000000000004}\n",
            "{'No': 0.108, 'Yes': 0.016000000000000004}\n",
            "{'No': 0.048, 'Yes': 0.024000000000000004}\n",
            "{'No': 0.03200000000000001, 'Yes': 0.09600000000000002}\n",
            "Train Accuracy: 80.0\n",
            "{'No': 0.04800000000000001, 'Yes': 0.06400000000000002}\n",
            "prediction 1:- [['Red' 'Sports' 'Domestic']] ---> ['Yes']\n",
            "\n",
            "\n",
            "{'No': 0.072, 'Yes': 0.024000000000000004}\n",
            "prediction 2:- [['Yellow' 'SUV' 'Imported']] ---> ['No']\n"
          ]
        }
      ]
    }
  ]
}